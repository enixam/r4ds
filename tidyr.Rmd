
# tidyr: Tidy data 


```{r, message = FALSE}
library(tidylog) # Tidylog provides feedback about dplyr and tidyr operations.
library(lubridate)
```

```{r, echo = FALSE}
knitr::opts_chunk$set(message = TRUE)
```



## Tidy data {#tidyr-intro}

> “Happy families are all alike; every unhappy family is unhappy in its own way.” 
> –– Leo Tolstoy    
> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” 
> –– Hadley Wickham

整洁的数据(Tidy data)是进行数据操作和 ggplot2 可视化的基础，所谓数据整理（清洗、清理），就是把 messy data 转换为 tidy data 的过程。在 tidyverse 生态中，**tidyr** 负责数据的整理和变型：




如果一个数据集是整洁的，需要满足以下三个要素：  
1. 每个变量有一个专属列 (Each variable must have its own column)  
2. 每个观测有一个专属行 (Each observation must have its own row)  
3. 每个值有一个专属的存储单元 (Each value must its own cell)  

```{r,echo = FALSE}
knitr::include_graphics("images/11.png")
```


这三条规则是互相关联的，不可能只满足三条规则中的两条，所以我们可以更简化地把清洁数据的要求写成：  
1. 每列是一个变量(Variables go in columns)  
2. 每行是一个观测(Observatiosn go in rows)



同样的数据可以有不同的表现形式，但只有满足整洁数据的三个条件的数据集才是最容易使用的。以下的 3 个数据集背后的均来自1999年和2000年世界卫生组织在阿富汗、巴西和中国的一次肺结核病例调查，都有 `country`、`year`、`cases` 和 `population`四个变量，但采用了不同的组织方式:

```{r}
table1
table2
table3
```

`table4a` 和 `table4b`分别是以 cases 和 population 为值的数据透视表：  
```{r}
table4a
table4b
```



在上面的例子中，只有`table1` 符合清洁数据的标准。在`table2` 中，`type`不是一个变量，它的值 `cases` 和 `population` 才是变量，进而导致了每一行不是一个完整的观测。在 `table3` 中，`rate` 同样不是一个变量，`cases` 和 `population` 的值被挤在了一个单元里。至于 `table4a` 和`table4b`，`1999` 和 `2000`不是变量，而是一个表示年份的变量的值。  

为什么要为获得清洁的数据如此大费周折呢？主要有两个优点：  

1. 清洁数据的规则使得我们可以遵从一个一致、明确的结构存储数据。学习处理这些数据的工具变得很容易，因为你的对象在底层是一致的。  
2. 把变量存储在列中可以把 R 的向量化函数优势发挥到极致。例如 `mutate()` 和 `summarize()` ，许多内置的 R 函数都是对向量进行操作的。只要有了清洁的数据，后面的数据变换工作就很容易： 

```{r}
# Compute rate per 10,000
table1 %>% 
  mutate(rate = cases / population * 10000)
# Compute cases per year
table1 %>%
  group_by(year) %>%
  summarize(cases = sum(cases)) 
# 或者：
table1 %>% 
  count(year, wt = cases)
# Visualise changes over time
library(ggplot2)
ggplot(table1, aes(year, cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))+
  scale_x_continuous(breaks = c(1999,2000),labels = c("1999","2000"))
```

### Exercises  

```{exercise}
用 `table2` 计算发病率 (`rate` = `cases` / `population`), 需要进行以下四步操作：
  * 得到每个国家每年的`cases`  
  * 得到每个国家每年的`population`  
  * 计算 `rate` = `cases` / `population`  
  * 把算好的数据存储到正确的位置 
```

  
首先，分别对 `cases` 和`population`建立一张表，并且确保两张表的排列顺序相同：  

```{r}
table2
(t2_cases <- filter(table2, type == "cases") %>%
  rename(cases = count) %>%
  arrange(country, year))
(t2_population <- filter(table2, type == "population") %>%
  rename(population = count) %>%
  arrange(country, year))
```

计算 `rate`  
```{r}
t2_cases_per_cap <- tibble(
  t2_cases$country,
  t2_cases$year,
  cases = t2_cases$cases,
  population = t2_population$population
)
t2_cases_per_cap
t2_cases_per_cap %>%
  mutate(rate = cases/population) %>%
  select(1,2,5) %>%  
  # 改变列名
  mutate(
    country = t2_cases$country,
    year = t2_cases$year
  ) %>%
  select(country, year, rate)
```

## Pivoting  


<center>
```{r, fig.cap="More images at https://www.garrickadenbuie.com/project/tidyexplain/#spread-and-gather", echo = FALSE}
knitr::include_graphics("images/12.jpg")
```
</center>

细看两表，不难发现它们实质上相同的数据(相对于第二张表，第一张是以 id 为行字段，key 为列字段，val 为值的数据透视表)。第一种称为**宽数据 (wide data,Cartesian data,笛卡尔型数据)**，需要看行和列的交叉点来找到对应的值。而第二种形式称为**长数据(long data,indexed data，指标型数据)**，在长数据（指标型）数据汇总，你需要看指标来找到需要变量的数值（变量x，y，z的值）。。很难简单地说哪一种格式更优，因为两种形式都有可能是整洁的，这取决于值"A"、"B"、"C"、"D"的含义。  


数据整理常需要化宽为长，但偶尔也需要化长为宽, **tidyr** 分别提供了c`pivot_longer()` 和 `pivot_wider()` 来实现以上两种形式的转换操作(统称为 **pivoting**)。在 [tidyr 1.0.0](https://www.tidyverse.org/articles/2019/09/tidyr-1-0-0/) 及更早的版本中，`gather()` 和 `spread()` 分别承担相同的工作，实际效果与 `pivot_` 函数一样，但后者有更易理解的命名和 api。 

```r
pivot_longer(data, 
  cols,
  names_to = "name",
  values_to = "value",)
```

```r
pivot_wider(data, 
  names_from = name,
  values_from = value)
```

`names_to` 和 `values_to` 参数相当于原来 `gather()` 中的 `key` 和 `value`，其中 “键” 列的默认名称变为 “name”   
同理, `names_from` 和 `values_from` 相当于原来 `spread()` 中的 `key` 和 `value`

```{r, echo = FALSE}
knitr::include_graphics("images/gather-spread.gif")
```



### `pivot_longer()`  

`tidyr::relig_income` 是一个典型的宽数据，除第一列以外的所有列表示收入的不同水平，值表示对应的人数：

```{r}
relig_income 
relig_income %>% pivot_longer(-religion, 
                              names_to = "income", 
                              values_to = "population")
```

另一个例子：美国劳工市场的月度数据，首先创建一个 messy data：  


```{r}
ec2 <- economics %>% as_tibble() %>%
  transmute(year =  year(date),
            month = month(date),
            rate = unemploy) %>%
  filter(year > 2005) %>% 
  pivot_wider(names_from = "month", values_from = "rate")
ec2
```

化宽为长：  

```{r}
ec2 %>% 
  pivot_longer(-year, names_to = "month", values_to = "value")
```

以上就是 `pviot_longer` 的基本用法，下面来处理一些更复杂的情况。  


#### Numeric data in column names

`pivot_longer()` 提供了 `names_ptype` 和 `values_ptypes` 调整数据集变长后键列和值列的数据类型。看一下 `billboard` 数据集：  

```{r}
billboard
```

显然，我们希望将所有以 `"wk"`开头的列聚合以得到整洁数据，键列和值列分别命名为 “week” 和 “rank”。另外要考虑的一点是，我们很可能之后想计算歌曲保持在榜单上的周数，故需要将 “week” 列转换为数值类型：  

```{r}
billboard_tidy <- billboard %>% 
  pivot_longer(cols = starts_with("wk"),
               names_to = "week",
               values_to = "rank",
               names_prefix = "wk",
               names_ptypes = list(week = integer()),
               values_drop_na = T)
```

```{r}
billboard_tidy
```


`names_prefix` 去除前缀 "wk"(否则无法从字符串转换为数值)，`names_ptype` 以列表的形式转换键列的数据类型。同理, `values_ptype` 可以转换值列的数据类型。  

```{r}
## 计算保持周数
billboard_tidy %>% 
  group_by(track) %>% 
  summarise(stay = max(week) - min(week) + 1) %>% 
  arrange(desc(stay))
```


#### Many variables in column names

在 tidyr 1.0.0 之前，当进行一定处理后发现多个变量被糅合到一列中时，可能会考虑使用 `separate()` 或者 `extract()`:   

```{r}
who
## 原书 tidyr 一章中使用的方法
who %>% 
  gather(starts_with("new"), 
         key = key, 
         value = value,
         na.rm = T) %>% 
  extract(key,
          into = c("diagnosis", "gender", "age"),
          regex = "new_?(.*)_(.)(.*)")
```

现在，`pivot_longer()` 现在可以在化宽为长的下一步直接完成拆分任务，可以直接在 `names_to` 中传入一个向量表示分裂后的各个键列，并在 `names_sep`(分隔符) 或者 `names_pattern` 中(正则表达式)指定分裂的模式：  

```{r}
who %>% 
  pivot_longer(starts_with("new"),
               names_to = c("diagonosis", "gender", "age"),
               names_pattern = "new_?(.*)_(.)(.*)",
               values_to = "count",
               values_drop_na = T)
```

更进一步，顺便设定好整理后 `gender` 和 `age` 的类型：  

```{r}
who %>% 
  pivot_longer(cols = starts_with("new"),
               names_to = c("diagonosis", "gender", "age"),
               names_pattern = "new_?(.*)_(.)(.*)",
               names_ptypes = list(
                 gender = factor(levels = c("f", "m")),
                 age = factor(
                        levels = c("014", "1524", "2534", "3544", "4554", "5564", "65"), 
                        ordered = TRUE)
               ),
               values_to = "count",
               values_drop_na = T)
```



#### Multiple observations per row

(多个值列)  

So far, we have been working with data frames that have one observation per row, but many important pivotting problems involve multiple observations per row. You can usually recognise this case because **name of the column that you want to appear in the output is part of the column name in the input**. In this section, you’ll learn how to pivot this sort of data.  

```{r}
family <- tribble(
  ~family,  ~dob_child1,  ~dob_child2, ~gender_child1, ~gender_child2,
       1L, "1998-11-26", "2000-01-29",             1L,             2L,
       2L, "1996-06-22",           NA,             2L,             NA,
       3L, "2002-07-11", "2004-04-05",             2L,             2L,
       4L, "2004-10-10", "2009-08-27",             1L,             1L,
       5L, "2000-12-05", "2005-02-28",             2L,             1L,
)
family <- family %>% mutate_at(vars(starts_with("dob")), ymd)
family
```

理想中的数据格式(两个值列)

|family|child|dob|gender
|:-:|:-:|:-:|:-:|
1|1|1998-11-26|1
1|2|2000-01-29|2
2|1|1996-06-22|2
3|1|2002-07-11|2
3|2|2004-04-05|2
4|1|2004-10-10|1
4|2|2009-08-27|1
5|1|2000-12-05|2
5|2|2005-02-28|1



Note that we have two pieces of information (or values) for each child: their `gender` and their `dob` (date of birth). These need to go into separate columns in the result. Again we supply multiple variables to `names_to`, using `names_sep` to split up each variable name. Note the special name `.value`: this tells `pivot_longer()` that that part of the column name specifies the “value” being measured (which will become a variable in the output)  

`.value` 在这里指代 `dob` 和 `gender` 两个值列
```{r}
family %>% 
  pivot_longer(
    -family, 
    names_to = c(".value", "child"),   ## child 为每个 family 中的标识变量
    names_sep = "_", 
    values_drop_na = TRUE
  )
```


在这里，`dob_child1`、`dob_child2`、`gender_child1`、`gender_child2`四个列名的**后半部分**被当做键列的值。例如，可以认为对于 `family == 1`的观测，首先生成了如下的结构：  

|family|child|dob|dob|gender|gender|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:
|1|child1|1998-11-16|2000-01-29|1|2|
|2|child2|||||

而后名称相同的值列合并：  

|family|child|dob|gender
|:-:|:-:|:-:|:-:|
1|child1|1998-11-26|1
1|child2|2000-01-29|2


另一个例子：  

```{r}
anscombe 
anscombe %>% 
  pivot_longer(everything(),
               names_to = c(".value", "set"),
               names_pattern = "([xy])([1234])")
```

叕一个例子：  

```{r}
pnl <- tibble(
  x = 1:4,
  a = c(1, 1,0, 0),
  b = c(0, 1, 1, 1),
  y1 = rnorm(4),
  y2 = rnorm(4),
  z1 = rep(3, 4),
  z2 = rep(-2, 4),
)
pnl
```

```{r}
pnl %>% 
  pivot_longer(-(x:b),
               names_to = c(".value", "time"),
               names_pattern = "([yz])([12])")
```


#### Duplicated column names

如果某个数据框中各列有重复的名字，用 `gather()` 聚合这些变量所在的列时会返回一条错误：  

```r
Error: Can't bind data because some arguments have the same name
```
这是因为被聚合的列名被当做 `key` 列的值，又因这些值是重复的，故不能唯一标识一条记录。`pivot_longer()` 针对这一点做了优化，尝试聚合这些列时，会自动生成一个标识列：  
```{r}
#  To create a tibble with duplicated names
# you have to explicitly opt out of the name repair 
# that usually prevents you from creating such a dataset:
(df <- tibble(x = 1:3, y = 4:6, y = 5:7, y = 7:9, .name_repair = "minimal")) 
```
```{r}
df %>% 
  pivot_longer(-x, names_to = "y")
```

### `pivot_wider()`

`pivot_wider()` 是 `pivot_longer()` 的逆操作，虽然在获得 tidy data 上，前者没有后者常用，但它经常被用来创建一些 summary table。  

`fish_encounters` 数据记录了一些沿河观测站对一批鱼群的观测情况(`seen` 为发现次数)：

```{r}
fish_encounters
```

很多后续分析工具需要每个观测站的观测情况单独成一列，使用 `pivot_wider()`:  

```{r}
# 数据中已有的列不需要引号便可引用
fish_encounters %>% 
  pivot_wider(names_from = station, values_from = seen)
```

关于 `pivot_wider()`，很重要的一点是它会暴露出数据中的隐式缺失值(implicit missing value)。这些没有出现在原数据中的 NA 值不是源自于记录错误或者遗失，只是没有对应的观测而已（观测站只能记录发生了的观测）。参数 **values_fill** 可以以一个列表填充 `pivot_wider()` 结果中的 NA， 当然如何处理这些隐式缺失值要按具体情境而定，在鱼群的例子里，用 0 填充是合适的：  

```{r}
fish_encounters %>% 
  pivot_wider(names_from = station, values_from = seen,
              values_fill = list(seen = 0))
```

```{block2, type = "todo"}
`fish_encoutners` 的贡献者 [Myfanwy Johnston](https://fishsciences.github.io/post/visualizing-fish-encounter-histories/) 在个人网站上有一篇相关的文章  
```

#### Aggregation  

`pivot_wider()` 可以用来执行一些简单的聚合操作。`warpbreaks` 是一个关于经纱强度的控制试验，每个处理 `(wool, tension)` 上进行了 9 次试验：

```{r}
(warpbreaks <- warpbreaks %>% as_tibble() %>% select(wool, tension, breaks))
warpbreaks %>% count(wool, tension)
```

现在想知道每个处理下的平均断头次数，只需展开 `wool` 或 `tension` 中的任意一个：  

```{r, message = TRUE, warning = TRUE}
warpbreaks %>% 
  pivot_wider(names_from = wool, values_from = breaks)
```

由于 `(wool, tension)` 不能唯一确认一个观测，多个观测被压缩至一个列表中，`values_fn(breaks = mean)` 求得平均值：  

```{r}
warpbreaks %>% 
  pivot_wider(names_from = wool, values_from = breaks,
              values_fn = list(breaks = mean))
```

For more complex summary operations, I recommend summarising before reshaping, but for simple cases it’s often convenient to summarise within `pivot_wider()`  

#### Generate column name from multiple variables  

现有一个数据集存储了关于产品、生产国家、生产年份和产量的水平组合：  

```{r}
production <- expand_grid(
    product = c("A", "B"), 
    country = c("AI", "EI"), 
    year = 2000:2014
  ) %>%
  filter((product == "A" & country == "AI") | product == "B") %>% 
  mutate(production = rnorm(nrow(.)))

production
```

假设现在希望对于每个 `product` 和 `country` 的组合均创建一列，关键是在 `names_from` 中传入一个向量：

```{r}
production %>% 
  pivot_wider(names_from = c(product, country), values_from = production)
```

`names_sep` 可以指定除了 `_` 以外的分隔符。`names_prefix` 为展开后的各列**添加**前缀(as opposed to removing in `pivot_longer()`)

#### Multiple value columns  

The `us_rent_income` dataset contains information about median income and rent for each state in the US for 2017 (from the American Community Survey, retrieved with the **tidycensus** package).  

```{r}
us_rent_income
```

Here both `estimate` and `moe` are values columns, so we can supply them to `values_from`:

```{r}
us_rent_income %>% pivot_wider(names_from = variable, values_from = c(estimate, moe))
```

Note that the name of the variable is automatically appended to the output columns.

#### When there is no identifying variable   {#contact}

A final challenge is inspired by [Jiena Gu](https://github.com/jienagu/tidyverse_examples/blob/master/example_long_wide.R). Imagine you have a contact list that you’ve copied and pasted from a website: 

```{r}
contacts <- tribble(
  ~field, ~value,
  "name", "Jiena McLellan",
  "company", "Toyota", 
  "name", "John Smith", 
  "company", "google", 
  "email", "john@google.com",
  "name", "Huxley Ratcliffe"
)
contacts
```

This is challenging because there’s no variable that identifies which observations belong together. 

直接化宽时，出现列表列（没有第三个标识变量）
```{r}
contacts %>% pivot_wider(names_from = field, values_from = value)
```


We can fix this by noting that every contact starts with a name, so we can create **a unique id** by counting every time we see “name” as the `field`:   

```{r}
(contacts <- contacts %>% 
  mutate(
    person_id = cumsum(field == "name")
  ))
```

```{r}
contacts %>% 
  pivot_wider(names_from = field, values_from = value)
```


### Combining `pivot_longer()` and `pivot_wider()`  

Some problems can’t be solved by pivotting in a single direction. The examples in this section show how you might combine `pivot_longer()` and `pivot_wider()` to solve more complex problems.


#### world bank data  

`world_bank_pop` contains data from the World Bank about population per country from 2000 to 2018.

```{r}
world_bank_pop
```

It’s not obvious exactly what steps are needed yet, but I’ll start with the most obvious problem: `year` is spread across multiple columns.

```{r}
pop2 <- world_bank_pop %>% 
  pivot_longer(`2000`:`2017`, names_to = "year", values_to = "value")
pop2
```

Next we need to consider the `indicator` variable:

```{r}
world_bank_pop %>% count(indicator)
```

Here `SP.POP.GROW` is population growth, `SP.POP.TOTL` is total population, and `SP.URB.*` are the same but only for urban areas. Let’s split this up into two variables: `area` (total or urban) and the actual variable (population or growth):

```{r}
# Use NA to omit the variable in the output.
pop3 <- pop2 %>% 
  separate(indicator, c(NA, "area", "variable"), sep = "\\.")  # sep takes a regex
pop3
```

Now we can complete the tidying by pivoting `variable` and `value` to make `TOTL` and `GROW` columns:

```{r}
pop3 %>% 
  pivot_wider(names_from = variable, values_from = value)
```
  

#### mutli choice data   

Based on a suggestion by Maxime Wack, https://github.com/tidyverse/tidyr/issues/384), the final example shows how to deal with a common way of recording multiple choice data. Often you will get such data as follows:

```{r}
(multi <- tribble(
  ~id, ~choice1, ~choice2, ~choice3,
  1, "A", "B", "C",
  2, "C", "B",  NA,
  3, "D",  NA,  NA,
  4, "B", "D",  NA
))
```

But the actual order isn’t important, and you’d prefer to have the individual questions in the columns. You can achieve the desired transformation in two steps. First, you make the data longer, eliminating the explcit `NA`s, and adding a column to indicate that this choice was chosen: 

```{r}
multi2 <- multi %>% 
  pivot_longer(-id, values_drop_na = TRUE) %>% 
  mutate(checked = TRUE)
multi2
```

Then you make the data wider, filling in the missing observations with `FALSE`; note the use of `id_cols = id` here, this eliminated the `name` column and combines mutilples rows per person into one row, since we don't need `name` in identifying an observation:

```{r}
multi2 %>% 
  pivot_wider(id_cols = id,
              names_from = value, values_from = checked, 
              values_fill = list(checked = FALSE))
```


### Exercises  

```{exercise}
在下面的例子中，研究为什么 `pivot_longer()` 和 `pivot_wider()` 不是完美对称的
```

```{r}
(stocks <- tibble(
  year = c(2015, 2015, 2016, 2016),
  half = c(1, 2, 1, 2),
  return = c(1.88, 0.59, 0.92, 0.17)
))
stocks %>%
  pivot_wider(names_from = year, values_from = return) %>%
  pivot_longer(-half, names_to = "year", values_to = "return")
```

先后使用 `pivot_wider()` 和 `pivot_longer()`无法得到一个相同的数据集（除了列的顺序）是因为，数据整理有时会丢失列的类型信息。当 `pivot_wider()` 将变量 `year` 的值 `2015` 和 `2016` 用作列的名字时，它们自然被转化为了字符串`"2015"`和`"2016"`；随后 `pivot_longer()` 把列名用作键列`year`的值，从而`year`自然变成了一个字符向量，可以用 `names_ptypes` 避免这一点  
。  
```{r}
stocks %>%
  pivot_wider(names_from = year, values_from = return) %>%
  pivot_longer(-half, names_to = "year", values_to = "return",
               names_ptypes = list(year = double()))
```


```{exercise}
为什么下面的数据框不能应用 `pivot_wider()`？可以添加一列解决这个问题吗？  
```

```{r,message = FALSE, warning = FALSE}
(people <- tribble(
  ~name, ~key, ~value,
  "Phillip Woods", "age", 45,
  "Phillip Woods", "height", 186,
  "Phillip Woods", "age", 50,
  "Jessica Cordero", "age", 37,
  "Jessica Cordero", "height", 156
))

people %>% 
  pivot_wider(names_from = key, values_from = value)
```

这个例子和 \@ref(contact) 中的 `contact` 很类似，虽然这里有第三列 `name`，但仍不足以唯一标识任意观测


因为这个数据集里有两个对于 "Phillip Woods" 在 `age` 上年龄的观测，`pivot_wider()` 就要把由`(Phillips Woods, age)`确定的单元格里“塞进两个值”。本质上因为 `name` 和 `key` 这两个变量上的值不能唯一确定一行，所以我们只要添加一列，让`name`、`key`和新列可以唯一确定一行即可： 
```{r}
people %>% 
  mutate(id = row_number()) %>% 
  pivot_wider(names_from = key, values_from = value)
```

## Nesting

Nesting creates **a list-column of data frames**; unnesting flattens it back out into regular columns. Nesting is a *implicitly  summarising operation*: you get one row for each group defined by the non-nested columns. This is useful in conjunction with other summaries that work with whole datasets, most notably models.

Since a nested data frame is no more than a data frame where one (or more) list-columns of data frames. You can create simple nested data frames by hand:  

```{r}
# df1 is a nested data frame
(df1 <- tibble(
  g = c(1, 2, 3),
  data = list(
    tibble(x = 1, y = 2),
    tibble(x = 4:5, y = 6:7),
    tibble(x = 10)
  )
))
```

Or more commonly, we can create nested data frames using `tidyr::nest()`. `df %>% nest(x, y)` specifies the columns to be nested; i.e. the columns that will appear in the inner data frame. Alternatively, you can `nest()` a grouped data frame created by `dplyr::group_by()`. The **grouping variables remain in the outer data frame and the others are nested**. The result preserves the grouping of the input.

**Variables supplied to nest() will override grouping variables** so that `df %>% group_by(x, y)` %>% `nest(z)` will be equivalent to `df %>% nest(z)`.

```{r}
df2 <- tribble(
  ~g, ~x, ~y,
   1,  1,  2,
   2,  4,  6,
   2,  5,  7,
   3, 10,  NA
)
df2 %>% nest(data = c(x, y))
```

```{r}
# grouped nesting
df2 %>% 
  group_by(g) %>% 
  nest()

# equal to 
df2 %>%
  group_nest(g)
```

**Nesting is easiest to understand in connection to grouped data**: each row in the output corresponds to one group in the input. We’ll see shortly this is particularly convenient when you have other per-group objects.

The opposite of `nest()` is `unnest()`. You give it the name of a list-column containing data frames, and it row-binds the data frames together, repeating the outer columns the right number of times to line up.  

```{r}
df1 %>% unnest(data)
```

`dplyr::group_split()` put each nested tibble in a list, similar to `base::split()`:  
```{r}
df2 %>% group_split(g)
```


### Example: Managing multiple models

Nested data is a great fit for problems where you have one of something for each group. A common place this arises is when you’re **fitting multiple models**.  

```{r}
gapminder <- gapminder::gapminder
gapminder_nest <- gapminder %>% 
  mutate(year1950 = year - 1950) %>% 
  group_nest(continent, country)

gapminder_nest
```

Now `gapminder_nest` is a tibble with 142 rows representing 142 countries with their respective time series data from 1952 - 2007 stored in the list column `data`. Then we can combine `mutate()` and `map` to create a new column to fit a linear model for each country:  

```{r}
mod_fit <- function(data) {
  lm(lifeExp ~ year1950, data = data)
}

gapminder_model <- gapminder_nest %>% 
  mutate(model = map(data, mod_fit))
gapminder_model
```

Then use `broom` functions to generate "tidy" model summaries:  

```{r}
gapminder_summary <- gapminder_model %>% 
  mutate(
    glance = map(model, broom::glance),
    tidy = map(model, broom::tidy),
    augment = map(model, broom::augment)
  )

gapminder_summary
```

`unnest()` each column: 

```{r}
# which country has the best fit
gapminder_summary %>% 
  unnest(glance) %>% 
  arrange(desc(r.squared))


gapminder_summary %>% 
  unnest(tidy)

gapminder_summary %>% 
  unnest(augment)
```

A similar case can be found at \@ref(viz-many-models)

### Example: Multicple hoice data  {#multi-choice}

```{r}
multiple_choice <- tibble(method = c(
  "CNNs",
  "Bayesian, Logistic Regression",
  "Data Visualization, Decision Trees",
  "Linear Regression, A/B Testing",
  "Data Visualization, Text Analytics"
))

multiple_choice %>% 
  mutate(method = str_split(method, ",")) %>% 
  unnest(method)
```

The trick here is that `str_split()` creates a list column, and then `unnest()` can unnest the column. A more general function `separate_rows()` in this case can be found at \@ref(separate)


Then we can do `count()` and plot the most frequent methods mentioned.  

## Rectangling  

**Rectangling** is the art and craft of taking a deeply nested list (often sourced from wild caught JSON or XML) and taming it into a tidy data set of rows and columns. There are three functions from tidyr that are particularly useful for rectangling:

- `unnest_longer()` takes each element of a list-column and makes a new row.
- `unnest_wider()` takes each element of a list-column and makes a new column.
- `unnest_auto()` guesses whether you want `unnest_longer()` or `unnest_wider()`.
- `hoist()` is similar to unnest_wider() but only plucks out selected components, and can reach down multiple levels.  

A very large number of data rectangling problems can be solved by combining these functions with a splash of `dplyr` (largely eliminating prior approaches that combined `mutate()` with multiple `purrr::map()`s).

To illustrate these techniques, we’ll use the **repurrrsive** package, which provides a number deeply nested lists originally mostly captured from web APIs.

```{r}
library(repurrrsive)
```

### Github users  

We’ll start with `gh_users`, a list which contains information about six GitHub users. 

```{r}
listviewer::jsonedit(gh_users)
```
Each user is a named list, where each element represents a column: 



To begin, we put the gh_users list into a data frame:

```{r}
(users <- tibble(user = gh_users))
```

Each element of column `user` is yet another list, where each element represents a column.

```{r}
names(users$user[[1]])
```

Obviously we could use `unnest_wider()` to turn the list components into columns:  

```{r}
users %>% unnest_wider(user)
```

But in this case, there are many components and we don’t need most of them so we can instead use `hoist()`. `hoist()` allows us to pull out selected components using the same syntax as `purrr::pluck()`:

```{r}
users %>% hoist(user,
                followers = "followers",
                login = "login",
                url = "html_url")
```

`hoist()` 从列表列中提取出指明的元素作为新变量，保留余下的元素 

`hoist()` removes the named components from the user list-column, so you can think of it as moving components out of the inner list into the top-level data frame  

### Github repos

We start off `gh_repos` similarly, by putting it in a tibble:  

```{r}
repos <- tibble(repo = gh_repos)
repos
```

By comparison, `gh_repos` is more nested than `gh_users`, with elements in the 2nd hierarchy being repositorys that `gh_users` own, and thus requires one more level of information to record each repo.  

```{r}
listviewer::jsonedit(gh_repos)
```


This time the elements of user are a list of repositories that belong to that user. These are observations, so should become new rows, so we use `unnest_longer()` rather than `unnest_wider()`:

```{r}
repos <- repos %>% unnest_longer(repo)
repos
```

Now each rwo representes a repository, then we can use `unnest_wider()` or `hoist()`:

```{r}
repos %>% hoist(repo, 
  login = list("owner", "login"), 
  name = "name",
  homepage = "homepage",
  watchers = "watchers_count"
)
```

Note the use of `list("owner", "login")`: this allows us to **reach two levels deep inside of a list**  using the same syntax as `purrr::pluck()`. An alternative approach would be to pull out just owner and then put each element of it in a column:

```{r}
repos %>% 
  hoist(repo, owner = "owner") %>% 
  unnest_wider(owner)
```

Instead of looking at the list and carefully thinking about whether it needs to become rows or columns, you can use `unnest_auto()`. It uses a handful of heuristics to figure out whether `unnest_longer()` or `unnest_wider()` is appropriate, and tells you about its reasoning.

```{r, message = TRUE}
tibble(repo = gh_repos) %>% 
  unnest_auto(repo) %>% 
  unnest_auto(repo)
```


### Game of Throne characters   


`got_chars` has a similar structure to `gh_users`: it’s a list of named lists, where each element of the inner list describes some attribute of a GoT character. 

```{r}
listviewer::jsonedit(got_chars)
```

We start in the same way, first by creating a data frame and then by unnesting each component into a column:  

```{r}
chars <- tibble(char = got_chars)
chars
```

```{r}
chars2 <- chars %>% unnest_wider(char)
chars2
```

This is more complex than `gh_users` because some component of char are themselves a list, giving us a collection of list-columns:  

```{r}
chars2 %>% select_if(is.list)
```

What you do next will depend on the purposes of the analysis. Maybe you want a row for every book and TV series that the character appears in:

```{r}
chars2 %>% 
  select(name, books, tvSeries) %>% 
  pivot_longer(c(books, tvSeries), names_to = "media", values_to = "value") %>% 
  unnest_longer(value)
```

Or maybe you want to build a table that lets you match title to name:  

```{r}
chars2 %>% 
  select(name, title = titles) %>% 
  unnest_longer(title)
```


### Sharla Gelfand’s discography  

We’ll finish off with the most complex list, from Sharla Gelfand’s discography. We’ll start the usual way: putting the list into a single column data frame, and then widening so each component is a column. I also parse the date_added column into a real date-time:

```{r}
listviewer::jsonedit(discog)
```

```{r}
discs <- tibble(disc = discog) %>% 
  unnest_wider(disc) %>% 
  mutate(date_added = as.POSIXct(strptime(date_added, "%Y-%m-%dT%H:%M:%S"))) 

discs 
```

At this level, we see information about when each disc was added to Sharla’s discography, not any information about the `disc` itself. To do that we need to widen the basic_information column:

```{r, error = TRUE}
discs %>% unnest_wider(basic_information)
```

Unfortunately that fails because there’s an id column inside basic_information. We can quickly see what’s going on by setting `names_repair = "unique"`(default to `"check_unique"` which makes no name repair, but check they are unique):  

```{r}
discs %>% unnest_wider(basic_information, names_repair = "unique")
```

The problem is that basic_information repeats the id column that’s also stored at the top-level, so we can just drop that:
```{r}
discs %>% 
  unnest_wider(basic_information, names_repair = "unique") %>% 
  select(starts_with("id"))

discs %>% 
  select(-id) %>% 
  unnest_wider(basic_information)
```

Alternatively, we could use `hoist()`   

```{r}
discs %>% 
  hoist(basic_information,
    title = "title",
    year = "year",
    label = list("labels", 1, "name"),
    artist = list("artists", 1, "name")
  )
```


A more systematic approach would be to create separate tables for artist and label:

```{r}
# table for artist
discs %>% 
  hoist(basic_information, artist = "artists") %>% 
  select(disk_id = id, artist) %>% 
  unnest_longer(artist) %>% 
  unnest_wider(artist)
```

```{r}
# table for label
discs %>% 
  hoist(basic_information, format = "formats") %>% 
  select(disk_id = id, format) %>% 
  unnest_longer(format) %>% 
  unnest_wider(format) %>% 
  unnest_longer(descriptions)
```



## `separate()` and `untie()`  

`separate()` 和 `untie()` 函数则是为了解决以下问题：多个变量挤在了同一列中，或者一个变量分散到了不同列中。  

### `separate()` {#separate}

```{r}
table3
```

在 `table3` 中，`rate` 同时包含了 `cases` 和 `population` 两个变量，我们需要把它拆分(separate)为两列，`separate()` 函数可以将这一混杂的列拆分成多个变量，它包含以下四个主要参数：  
* `data`: 需要调整的数据框  
* `col`: 需要进行拆分的列的列名  
* `into`:  拆分后新生成变量的列名，格式为字符串向量  
* `sep`: 对如何拆分原变量的描述，其可以是正则表达式，如 `_` 表示通过下划线拆分，或 `[^a-z]` 表示通过任意非字符字母拆分，或一个指定位置的整数。默认情况下，`sep`将认定一个非字符字母进行划分  
```{r}
# 这个例子里，sep 不是必需的
table3 %>%
  separate(col = rate,into = c("cases","population"))
```

整理的图示：  
```{r, echo = FALSE}
knitr::include_graphics("images/15.png")
```

注意，以上输出的tibble中，`cases` 和 `population`被设定为字符串类型，使用`convert = T`将其转换为数值变量

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), convert = T)
```


A seemingly similar function `tidyr::separate_rows()` separate existing columns based on `sep`, and then breaks each component into new rows, instead of columns:  

```{r}
df <- tibble(
  x = 1:3,
  y = c("a", "d,e,f", "g,h"),
  z = c("1", "2,3,4", "5,6")
)

df %>% separate_rows(y, z, sep = ",")
```

The multiple choice data mentioned in \@ref(multi-choice) can easily be solved when using `separate_rows()`:  

```{r}
multiple_choice %>% separate_rows(method, sep = ",")
```


### `unite()` 

`unite()` 是 `separate()` 的逆运算——它可以将多列合并为一列.
在 `table5` 中，原来的 `year` 变量被拆成了两个列，可以用 `unite()`，只需要指定要合并后的列名和要合并的列。默认情况下，新列中将用`_`分隔符
```{r}
table5
unite(table5, col = year, century, year)
```


`sep = ""` 可以取消分隔符：  
```{r}
unite(table5, col = year, century, year, sep="")
```

整理的图示：
```{r, echo = FALSE}
knitr::include_graphics("images/16.png")
```

```{r}
table6 <- unite(table5,col = year,century,year,sep="")
table5
```

### Exercises  

```{exercise}
`separate()`中的`extra`和`fill`参数的作用是什么？用下面两个数据框进行实验： 
```

```{r,error = T}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, into = c("one", "two", "three"))
tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, into = c("one", "two", "three"))
```

`extra` 用来告诉 `separate()` 函数如何处理分列过程中多出来的元素(too many pieces，即 `into` 指定的列数小于原数据中某行可分的元素个数)，`fill` 负责如何处理元素不够的情况(not enough pieces，即`into`指定的列数大于原数据中某行可分的元素个数)。默认情况下，`extra = "drop"`，`separate()` 将丢弃多余的元素，并生成一条警告信息：  

```{r}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, into = c("one", "two", "three"), extra = "drop")
```

`extra = "merge"`将把多余的元素和前一个元素当做一个整体：  
```{r}
tibble(x = c("a, b, c", "d, e, f, g", "h, i, j")) %>% 
  separate(x, c("one", "two", "three"), extra = "merge")
```
对于元素过少的情况，默认的`fill = "warn"`将会用`NA`进行填充，但会生成一条警告。`fill = "right"`会尽可能让靠左的列拥有可用的元素，用`NA`填充右边的列；`fill = "left"`正好相反。这两种手动设置都不会产生`warning`:  
```{r}
tibble(x = c("a, b, c", "d, e, ", "h, i, j")) %>% 
  separate(x, c("one", "two", "three"), fill = "left")

tibble(x = c("a,b,c", "d, e, ", "h, i, j")) %>% 
  separate(x, c("one", "two", "three"),fill = "right")
```
> 2.`unite()`和`separate()`均有一个`remove`参数，它的作用是什么？    
`remove`控制是否在`unite()`或`separate()`输出的数据框中保留原来的列，默认`remove = T`。如果想保留原来未合并/分离的格列，可以设置`remove = F`
```{r}
table5 
table5 %>% unite(col = year_unite,century,year,sep = "",remove = F)
```

```{exercise}
探究 **tidyr** 中一个与 `separate()` 类似的函数 `extract()` 的用法  
```


`separate()`函数的分列操作是基于参数 `sep` 的，无论是给 `sep` 传入字符串指定分隔符，还是用数值指定分隔的位置，`separate()` 必须要有一个分隔符才能正常运作（可以把`sep = n`看做第 n 个和第 n+1 个元素之间的一个空白分隔符）  
`extract()`用一个正则表达式`regex`描述要分隔的列`col`中存在的模式，在正则表达式中的每个子表达式(用`()`定义)将被认为是`into`中的一个元素，因此，`extract()`比`separate()`使用起来更加广泛灵活。例如下面的数据集无法用`separate()`分列，因为无法用一个各行的分隔符(的位置)不一样，但用`extract()`中的正则表达式就很简单：  
```{r}
tibble(x = c("X1", "X20", "AA11", "AA2")) %>%
  extract(x, c("variable", "id"), regex = "([A-Z]+)([0-9]+)")
```

适当设计`regex`，实现的效果可以与设置`sep`完全一致：  

```{r}
# example with separators
tibble(x = c("X_1", "X_2", "AA_1", "AA_2")) %>%
  extract(x, c("variable", "id"), regex = "([A-Z]+)_([0-9])")
# example with position
tibble(x = c("X1", "X2", "Y1", "Y2")) %>%
  extract(x, c("variable", "id"), regex = "([A-Z])([0-9])")
```


## Handling missing values {#tidyr-missing}

数据整理改变了数据的呈现方式，随之而来的一个话题便是缺失值。通常当我们泛泛地使用"缺失值 (missing value)" 这个名词的时候，其实是指以下两种"缺失"方式中的某一种：  

* 显式缺失(Explicitly missing): 在数据中用 `NA` 标识  

* 隐式缺失(Implicitly missing): 未出现在数据中的值   

*R for Data Science* 中对这两种缺失的概括：  
> An explicit missing value is the presence of an absence; an implicit missing value is the absence of a presence.


通过一个简单的数据框区分两种数据缺失的方式：  

```{r}
stocks <- tibble(
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
stocks
```

我们很容易找到 `stocks` 第四条观测在 `return` 上的一个 `NA` ，因为它是显式缺失的。另一个隐式缺失的值是 `(year = 2016, qtr = 1)` 对应的观测，它没有出现在数据集中。  
数据呈现方式上的改变可以将隐式缺失值变成显式。比如，用 `pivot_wider()`函数构造以 `year` 为行字段，以 `return` 为值的透视表,这样就会产生一个属于水平 `(year = 2016, qtr = 1)`的单元格：  

```{r}
stocks %>%
  pivot_wider(names_from = year, values_from = return)
```

现在，再使用 `pivot_longer()` 不能得到原来的数据框，因为将比原来多出一行显示的缺失值
```{r}
stocks %>%
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(-qtr, names_to = "year", values_to = "return")
```

如果研究者认为这些缺失值是无足轻重的,`values_drop_na = TRUE` 将在 `pivot_longer()` 生成的数据框中移除含有缺失值的行，这会同时移除显式和隐式缺失值：  
```{r}
## 现在输出数据框比原来少一行
stocks %>%
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(-qtr, names_to = "year", values_to = "return",    
               values_drop_na = TRUE)
```


`fill()` 专门用来填充缺失值,它接受一些需要填充缺失值的列，并用最近的值调换 `NA`，`.direction` 参数控制用填充的方向：`direction = “up"` 将由下往上填充，`NA` 将被替换为它下面那一列的值；`direction = "donw"` 反之
```{r}
treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)
treatment %>%
  fill(person, .direction = "up")
treatment %>%
  fill(person, .direction = "down")
```

More useful methods dealing with missing values (in `tidyr` and other packages) are discussed in \@ref(dealing-with-missing-values)


## Case Study  {#tidyr-case}

To finish off the chapter, let’s pull together everything you’ve learned to tackle a realistic data tidying problem. The `tidyr::who` dataset contains tuberculosis (TB) cases broken down by year, country, age, gender, and diagnosis method. The data comes from the *2014 World Health Organization Global Tuberculosis Report*, available at [http://www.who.int/tb/country/data/download/en/](http://www.who.int/tb/country/data/download/en/).  
There’s a wealth of epidemiological information in this dataset, but it’s challenging to work with the data in the form that it’s provided:

```{r,message = F}
who
```
This is a very typical real-life example dataset. It contains redundant columns, odd variable codes, and many missing values. In short, `who` is messy, and we’ll need multiple steps to tidy it. Like `dplyr`, `tidyr` is designed so that each function does one thing well. That means in real-life situations you’ll usually need to string together multiple verbs into a pipeline.
The best place to start is almost always to gather together the columns that are not variables. Let’s have a look at what we’ve got:  
* It looks like `country`, `iso2`, and `iso3` are three variables that redundantly specify the country.  
* `year` is also a variable  
* We don’t know what all the other columns are yet, but given the structure in the variable names (e.g. `new_sp_m014`, `new_ep_m014`, `new_ep_f014`) these are likely to be values, not variables.  
So we need to pivot all the columns from `new_sp_m014` to `newrel_f65`. We don’t know what those values represent yet, so we’ll give them the generic name `"name"`. We know the cells represent the count of cases, so we’ll use the variable `cases`. There are a lot of missing values in the current representation, so for now we’ll use `values_drop_na = TRUE` just so we can focus on the values that are present.

```{r}
who1 <- who %>% 
  pivot_longer(-(1:4), names_to = "name", values_to = "cases", values_drop_na = TRUE)
who1
```
We can get some hint of the structure of the values in the new `name` column by counting them:  
```{r}
who1 %>% count(name)
```

You might be able to parse this out by yourself with a little thought and some experimentation, but luckily we have the data dictionary handy. It tells us:  
1. The first three letters of each column denote whether the column contains new or old cases of TB. **In this dataset, each column contains new cases**.  
2. The next two letters describe the type of TB:
  * `rel` stands for cases of relapse  
  * `ep` stands for cases of extrapulmonary TB  
  * `sn` stands for cases of pulmonary TB that could not be diagnosed by a pulmonary smear (smear negative)  
  * `sp` stands for cases of pulmonary TB that could be diagnosed be a pulmonary smear (smear positive)  
3. The sixth letter gives the sex of TB patients. The dataset groups cases by males (`m`) and females (`f`).
4. The remaining numbers gives the age group. The dataset groups cases into seven age groups:  
  * `014` = 0 – 14 years old  
  * `1524` = 15 – 24 years old  
  * `2534` = 25 – 34 years old  
  * `3544` = 35 – 44 years old  
  * `4554` = 45 – 54 years old  
  * `5564` = 55 – 64 years old  
  * `65` = 65 or older  
  
We need to make a minor fix to the format of the column names: unfortunately the names are slightly inconsistent because instead of `new_rel` we have `newrel` (it’s hard to spot this here but if you don’t fix it we’ll get errors in subsequent steps). You’ll learn about `str_replace()` in strings, but the basic idea is pretty simple: replace the characters `“newrel”` with `“new_rel”`. This makes all variable names consistent.

```{r}
who2 <- who1 %>% 
  mutate(key = stringr::str_replace(name, "newrel", "new_rel"))
who2
```

We can separate the values in each code with two passes of `extracct()`(This can also be done in the previous `pivot_longer()` step  by passing a vector to `names_to`). 

```{r}
who3 <- who2 %>% 
  extract(name, into = c("type", "sex", "age"),
          regex = "new_(\\w{2,3})_([fm])(\\d+)")

who3
```

Then, let’s also drop `iso2` and `iso3` since they’re redundant (see Exercise \@ref(exr:redundancy) below for proof).  

```{r}
who4 <- who3 %>% select(-iso2, -iso3)
```

Now `who4` is a tidy version of `tidyr::who`!  

## Miscellaneous Functions  

There are several remaining useful functions in `tidyr` that cannot be easily categorized.  


### `chop()` and `unchop()`  

Chopping and unchopping **preserve the width of a data frame, changing its length.** `chop()` makes `df` shorter by converting rows within each group into list-columns. `unchop()` makes `df` longer by expanding list-columns so that each element of the list-column gets its own row in the output.    

**Note that we get one row of output for each unique combination of non-chopped variables**: 

`chop()` differs from `nest()` in section \@ref(nesting) in that it does not collpase columns into a tibble, but into a list:   

```{r}
df <- tibble(x = c(1, 1, 1, 2, 2, 3), 
             y = 1:6, 
             z = 6:1)

df %>% chop(cols = c(y, z))

df %>% nest(data = c(y, z))
```



`unchop()`:  

```{r}
df <- tibble(x = 1:4, y = list(integer(), 1L, 1:2, 1:3))

df %>% unchop(y)
```

If there's a size-0 element (like `NULL` or an empty data frame), that entire row will be dropped from the output. If you want to preserve all rows, use `keep_empty = TRUE` to replace size-0 elements with a single row of missing values.

```{r}
# equivalent to df %>% unnest_longer(y)
df %>% unchop(y, keep_empty = TRUE)
```

```{r}
# Incompatible types -------------------------------------------------
# If the list-col contains types that can not be natively
df <- tibble(x = 1:2, y = list("1", 1:3))

try(df %>% unchop(y))

df %>% unchop(y, ptype = tibble(y = integer()))

df %>% unchop(y, ptype = tibble(y = character()))
  
df %>% unchop(y, ptype = tibble(y = list()))
```

**ptype**: Optionally, supply a data frame prototype for the output `cols`, overriding the default that will be guessed from the combination of individual value


### `uncount()`  

Performs the opposite operation to `dplyr::count()`, duplicating rows according to a weighting variable (or expression)  

```{r}
df <- tibble(x = c("a", "b", "c"), n = c(1, 2, 3))
uncount(df, n)
```

we can supply a string `.id` to create a new variable which gives a unique identifier for each created row:  

```{r}
uncount(df, n, .id = "id")
```

`uncount()` can be helpful in convertnig **frequency form data** to **case form data**, e.g:    

```{r}
fiber <- read_csv("data/Fiber.csv") 
fiber

fiber %>% uncount(count)
```

Other way that can achieve this transformation: `rep()`:  
```{r}
fiber[rep(1:nrow(fiber), fiber$count), -3]
```







### Exercises 

```{exercise redundancy}
在清理 `who` 数据集时，我们说`iso2`和`iso3`是冗余的，证明这一点
```


  
如果 `iso2` 和 `iso3` 是冗余的，则在数据集中对于变量组合 `(country, year)` 的每个值，都能唯一确定一个观测(因为 `(country, year)` 本身可以被用作键)。   

```{r}
who %>% 
  count(country, year) %>% 
  filter(n > 1)
```


另一个思路是 `distinct()` 函数，它将返回数据框中某些列出现的的全部不重复的水平组合（注意`complete()`是”制造出“全部可能的水平组合），和 `unique()` 类似，但速度更快： 

```{r}
who %>%
  distinct(country, iso2, iso3) %>%
  group_by(country) %>%
  summarize(n = n()) %>% 
  filter(n > 1)
```

## None-tidy data  {#non-tidy}

Before we continue on to other topics, it’s worth talking briefly about non-tidy data. Earlier in the chapter, I used the pejorative term “messy” to refer to non-tidy data. That’s an oversimplification: there are lots of useful and well-founded data structures that are not tidy data. There are two main reasons to use other data structures:  

* Alternative representations may have substantial performance or space advantages.  

* Specialised fields have evolved their own conventions for storing data that may be quite different to the conventions of tidy data.  

Either of these reasons means you’ll need something other than a tibble (or data frame). If your data does fit naturally into a rectangular structure composed of observations and variables, I think tidy data should be your default choice. But there are good reasons to use other structures; tidy data is not the only way.
If you’d like to learn more about non-tidy data, I’d highly recommend this thoughtful blog post by Jeff Leek: [http://simplystatistics.org/2016/02/17/non-tidy-data/](http://simplystatistics.org/2016/02/17/non-tidy-data/)  

